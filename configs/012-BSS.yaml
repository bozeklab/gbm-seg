trainer:
  # supervised, semi_seupervised
  mode: semi_supervised
  model:
    # unet_3d, undet_3d_me
    name: unet_3d
    # Huge: [128, 256, 512, 1024]
    # Big: [64, 128, 256, 512]
    # Medium: [64, 128, 256]
    # Small: [32, 64, 128]
    feature_maps: [64, 128, 256, 512]
    # 0: Nephrin
    # 1: WGA
    # 2: Collagen4
    channels: [0, 1, 2]
    # The kernel size and padding should
    # make sense and produces the same dimensions
    # as output at the end.
    encoder_kernel: [3, 3, 3]
    encoder_padding: 'same'
    decoder_kernel: [3, 3, 3]
    decoder_padding: 'same'
    # It can be differed from samples
    # Might add the functionality later
    number_class: 2

  optim:
    name: adam
    lr : 0.0005

  loss: CrossEntropy
  loss_weights: [1.0, 7.0]
  metrics: [accuracy, ]
  # Every report_freq batches, metrics and losses will be logged
  report_freq: 5

  epochs: 10
  # Every save_interval a snapshot will be created
  save_interval: 1
  snapshot_path: snapshots/

  result_path: /data/afatehi/gbm/results-train/
  skip_training: False

  unlabeled_ds:
    path: /data/afatehi/gbm/data/gbm_unlabeled_ds/
    batch_size: 24
    sample_dimension: [12, 256, 256]
    pixel_stride: [1, 64, 64]
    pin_memory: True
    # shuffle should be off when using DDP
    shuffle: False
    # Use this if the order of channels is
    # Different, for example use [1, 0, 2]
    # If the first channel is WGA and second is nephrin
    channel_map: [0, 1, 2]

  train_ds:
    path: /data/afatehi/gbm/data/gbm_train_ds/
    batch_size: 24
    sample_dimension: [12, 256, 256]
    pixel_stride: [1, 16, 16]
    pin_memory: True
    # shuffle should be off when using DDP
    shuffle: False
    # Use this if the order of channels is
    # Different, for example use [1, 0, 2]
    # If the first channel is WGA and second is nephrin
    channel_map: [0, 2, 1]

  valid_ds:
    path: /data/afatehi/gbm/data/gbm_valid_ds/
    batch_size: 24
    sample_dimension: [12, 256, 256]
    pixel_stride: [1, 16, 16]
    pin_memory: True
    # shuffle should be off when using DDP
    shuffle: False
    # Use this if the order of channels is
    # Different, for example use [1, 0, 2]
    # If the first channel is WGA and second is nephrin
    channel_map: [0, 2, 1]

  visualization:
    enabled: True
    # The chance for a batch to create visualization
    chance: 0.20
    path: gbm-vv/
    gif: True
    tif: True
    mesh: False

  tensorboard:
    enabled: True
    path: tensorboard/
    metrics: True

  device: cuda
  mixed_precision: True

  ddp:
    enabled: False
    no_of_nodes: 2
    rdzv_backend: c10d
    rdzv_endpoint: 192.168.227.235:29603

inference:
  model:
    # unet_3d, undet_3d_me
    name: unet_3d
    # Of course it should be the same as the checkpoint
    feature_maps: [64, 128, 256, 512]
    # 0: Nephrin
    # 1: WGA
    # 2: Collagen4
    channels: [0, 1, 2]
    number_class: 3

  snapshot_path: '~/gbm/results-train/unet_3d-adam-CrossEntropy-012-64128256512/snapshots/unet_3d-unet_3d-adam-CrossEntropy-012-64128256512-032.pt'
  device: cuda

  report_freq: 10
  save_npy: False

  result_dir: ~/gbm/results-infer/

  inference_ds:
    path: '~/gbm/data/raw/Batch 1/TifImages/'
    batch_size: 6
    sample_dimension: [12, 256, 256]
    pixel_stride: [1, 64, 64]
    pin_memory: True

logging:
  log_level: INFO
  log_file: logs/train.log
  log_std: True
  log_summary: False

